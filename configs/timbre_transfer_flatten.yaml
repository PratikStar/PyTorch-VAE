show_logs: True
log_level: 6

wandb:
  entity: "auditory-grounding"
  project: "try"
#  project: "timbre-transfer-flatten"

data_params:
  dataset_path: '../../data/timbre'
  batch_size: 32 # set this number twice as actual batch size
  num_workers: 0

  spectrogram:
    type: "stft" # "stft" or "mel"
    stft:
      spectrogram_dims: [256, 16]
    mel:
      frame_size: 1024
      hop_length: 256
      spectrogram_dims: [80, 63] # (mel_channels, n_frames)
      segment_signal_length: 16000
  saver: # saves spectrogram as npy and min/max values. TODO: Untested
    enabled: False
    save_dir: "../out" # relative to dataset_path
  visualizer:
    enabled: False # Please enable for spectrogram inference
    save_dir: "../out" # relative to dataset_path
  csv: # Log generated datapoints in a csv
    enabled: True
    path: "../log" # relative to dataset_path



model_params:
  name: 'TimbreTransferFlatten'
  timbre_encoder:
    spectrogram_dims: [1, 256, 16] # (C, H, W). dependant on data_params.spectrogram....
    conv2d_channels: [32, 64, 128, 256]
    stride: [2, 2]
    kernel_size: [5, 5] # 5X5 needs padding=2, and 7X7 needs padding=3. All when stride=2
    padding: [2, 2]
    latent_dim: 32
    converge_latent: "first"
  music_encoder:
    spectrogram_dims: [1, 256, 16] # (C, H, W). dependant on data_params.spectrogram....
    conv2d_channels: [32, 64, 128, 256]
    stride: [2, 2]
    kernel_size: [5, 5] # 5X5 needs padding=2, and 7X7 needs padding=3. All when stride=2
    padding: [2, 2]
    latent_dim: 256
  merge_encoding: "cat" # z di_b z
  decoder:
    di_spectrogram_dims: [1, 256, 16] # (C, H, W). dependant on data_params.spectrogram....
    conv2d_channels: [256, 128, 64, 32] # These are conv2d channels. Encoder: (1, 256, 64) -> (32, 128, 32) -> (64, 64, 16) -> (128, 32, 8) -> (256, 16, 4) -> (512, 8, 2)
    stride: [2, 2]
    kernel_size: [5, 5]
    padding: [2, 2]
    output_padding: [1, 1]
  loss:
    function: "L1"

#  load_path: "/work/gk77/k77021/repos/TimbreSpace/logs/TimbreTransfer/version_4/checkpoints/last.ckpt"


exp_params:
  LR: 0.0001
  weight_decay: 0.0
  kld_weight_timbre: 0.000001
  kld_weight_music : 0.000001
  manual_seed: 1265
  model_checkpoint: # Diecrtly passed to ModelCheckpoint()
    save_top_k: 100
    every_n_epochs: 50
    monitor: "val_loss"
    save_last: True



trainer_params: # This directly goes to trainer
  gpus: []
  max_epochs: 1000
  log_every_n_steps: 10


logging_params:
  save_dir: "logs/"
